{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "99b09685",
   "metadata": {},
   "source": [
    "# Coherent info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f660f1b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from coherentinfo.moebius_qubit import MoebiusCodeQubit\n",
    "from coherentinfo.moebius_odd_prime import MoebiusCodeOddPrime\n",
    "from coherentinfo.postprocess import (aggregate_data,\n",
    "                                      aggregate_data_jax,\n",
    "                                      update_aggregated_data_jax,\n",
    "                                      compute_conditional_entropy_term,\n",
    "                                      miller_madow_conditional_entropy)\n",
    "\n",
    "\n",
    "from coherentinfo.errormodel import ErrorModelBernoulli, ErrorModelPoisson\n",
    "# import galois\n",
    "import scipy\n",
    "import timeit\n",
    "import jax\n",
    "import jax.numpy as jnp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "486712a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "length = 7\n",
    "width = 7\n",
    "p = 3\n",
    "moebius_code = MoebiusCodeOddPrime(length=length, width=width, d=2 * p)\n",
    "moebius_code_qubit = MoebiusCodeQubit(length=length, width=width)\n",
    "h_z = moebius_code.h_z\n",
    "h_x = moebius_code.h_x\n",
    "logical_x = moebius_code.logical_x\n",
    "logical_z = moebius_code.logical_z"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e2447e23",
   "metadata": {},
   "outputs": [],
   "source": [
    "gamma = 0.01\n",
    "p_error = 0.1\n",
    "em_moebius_poisson_jax = ErrorModelPoisson(\n",
    "    moebius_code.num_edges, 2 * p, gamma)\n",
    "em_moebius_qubit = ErrorModelBernoulli(\n",
    "    moebius_code.num_edges, 2, p_error\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "607a308d",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_samples = 1_000_000\n",
    "num_batch = 1\n",
    "num_samples_batch = int(num_samples / num_batch)\n",
    "max_different_syndromes = 1_000_000  # upper bounded by num_samples\n",
    "# vertex_result = moebius_code_qubit.compute_batched_vertex_syndrome_chi_z(\n",
    "#     num_samples, em_moebius_qubit_jax)\n",
    "# seeds = [np.random.randint(100_000) for _ in range(num_batch)]\n",
    "# master_vertex_keys = jnp.array([jax.random.PRNGKey(seed) for seed in seeds])\n",
    "base_key = jax.random.PRNGKey(0)\n",
    "master_vertex_keys = jax.random.split(base_key, num_batch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "687f30e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# vertex_result = moebius_code.compute_batched_vertex_syndrome_chi_z(\n",
    "#     num_samples_batch, em_moebius_poisson_jax, master_vertex_keys[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "f788e8b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# aggregate_data_jit = jax.jit(\n",
    "#     aggregate_data_jax, static_argnums=(1,))\n",
    "# vertex_pads = -1 * jnp.ones(vertex_result.shape[1] - 1)\n",
    "\n",
    "# unique_syndromes, vertex_counts = aggregate_data_jit(\n",
    "#     vertex_result,\n",
    "#     max_different_syndromes,  # Passed as the static (Python int) argument\n",
    "#     vertex_pads\n",
    "# )\n",
    "\n",
    "init_syndromes = -1 * \\\n",
    "    jnp.ones([max_different_syndromes,\n",
    "             moebius_code.num_vertex_checks], dtype=jnp.int32)\n",
    "init_counts = jnp.zeros([max_different_syndromes, 2], dtype=jnp.int32)\n",
    "vertex_pads = -1 * jnp.ones(init_syndromes.shape)\n",
    "# del vertex_result\n",
    "update_aggregated_data_jit = jax.jit(\n",
    "    update_aggregated_data_jax, static_argnums=(3,))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "c2977e8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# for batch in range(0, num_batch):\n",
    "#     vertex_result = moebius_code.compute_batched_vertex_syndrome_chi_z(\n",
    "#         num_samples_batch,\n",
    "#         em_moebius_poisson_jax,\n",
    "#         master_vertex_keys[batch])\n",
    "\n",
    "#     unique_syndromes, vertex_counts = \\\n",
    "#         update_aggregated_data_jit(\n",
    "#             unique_syndromes,\n",
    "#             vertex_counts,\n",
    "#             vertex_result,\n",
    "#             max_different_syndromes,\n",
    "#             vertex_pads\n",
    "#         )\n",
    "\n",
    "#     del vertex_result\n",
    "\n",
    "def run_compiled_simulation(\n",
    "    master_keys,\n",
    "    num_samples_batch,\n",
    "    max_different_syndromes,\n",
    "    vertex_pads,\n",
    "    init_syndromes,\n",
    "    init_counts\n",
    "):\n",
    "    \"\"\"\n",
    "    Runs the entire sampling and aggregation loop inside a single XLA call.\n",
    "    \"\"\"\n",
    "\n",
    "    def scan_body(carry, key):\n",
    "        # 1. Unpack the current state (the 'carry')\n",
    "        current_syndromes, current_counts = carry\n",
    "\n",
    "        # 2. Sample (Ensure this function is fully JAX-native!)\n",
    "        # This part must be JAX-compatible to work inside scan.\n",
    "        vertex_result = moebius_code.compute_batched_vertex_syndrome_chi_z(\n",
    "            num_samples_batch,\n",
    "            em_moebius_poisson_jax,\n",
    "            key\n",
    "        )\n",
    "\n",
    "        # 3. Update using the JIT-compiled function we built\n",
    "        next_syndromes, next_counts = update_aggregated_data_jax(\n",
    "            current_syndromes,\n",
    "            current_counts,\n",
    "            vertex_result,\n",
    "            max_different_syndromes,\n",
    "            vertex_pads\n",
    "        )\n",
    "\n",
    "        # 4. Return the new state to be used in the next iteration\n",
    "        # The second return value (None) is for 'stacking' results,\n",
    "        # but we don't want to store per-batch results (to save RAM).\n",
    "        return (next_syndromes, next_counts), None\n",
    "\n",
    "    # This is where the magic happens.\n",
    "    # It loops over 'master_keys' entirely within XLA.\n",
    "    (final_syndromes, final_counts), _ = jax.lax.scan(\n",
    "        scan_body,\n",
    "        (init_syndromes, init_counts),\n",
    "        master_keys\n",
    "    )\n",
    "\n",
    "    return final_syndromes, final_counts\n",
    "\n",
    "\n",
    "# Compile the whole engine\n",
    "run_simulation_jit = jax.jit(run_compiled_simulation, static_argnums=(1, 2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "2890584a",
   "metadata": {},
   "outputs": [],
   "source": [
    "final_s, final_c = run_simulation_jit(\n",
    "    master_vertex_keys,\n",
    "    num_samples_batch,\n",
    "    max_different_syndromes,\n",
    "    vertex_pads,\n",
    "    init_syndromes,\n",
    "    init_counts\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "18cefe63",
   "metadata": {},
   "outputs": [],
   "source": [
    "# @jax.jit\n",
    "def count_unique_syndromes(unique_syndromes: jax.Array):\n",
    "    \"\"\"\n",
    "    Blazing fast count for sorted syndromes.\n",
    "    Finds the first occurrence of -1 in the first column.\n",
    "    \"\"\"\n",
    "    # We only care about the first element of each syndrome\n",
    "    first_elements = unique_syndromes[:, 0]\n",
    "\n",
    "    # Since searchsorted needs ascending order, we search for the\n",
    "    # first element that is NOT greater than -1 from the right,\n",
    "    # or we can just find the first -1 by checking 'is it -1'.\n",
    "\n",
    "    # This returns the number of elements that are NOT -1\n",
    "    # by finding the first index where the condition (val == -1) is true.\n",
    "    is_pad = (first_elements == -1)\n",
    "\n",
    "    # jnp.argmax on a boolean array returns the FIRST index where it's True\n",
    "    first_pad_idx = jnp.argmax(is_pad)\n",
    "\n",
    "    # EDGE CASE: If no pads exist, argmax returns 0.\n",
    "    # We check if the first element is actually a pad.\n",
    "    has_any_pad = is_pad[first_pad_idx]\n",
    "\n",
    "    return jnp.where(has_any_pad, first_pad_idx, unique_syndromes.shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "1976d8bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# count_unique_syndromes(unique_syndromes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "9db418c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# unique_syndromes.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "fe92ef57",
   "metadata": {},
   "outputs": [],
   "source": [
    "vertex_conditional_entropy = miller_madow_conditional_entropy(\n",
    "    final_c / num_samples, num_samples)\n",
    "# del vertex_probs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "5d53837e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-0.3984625\n"
     ]
    }
   ],
   "source": [
    "print(vertex_conditional_entropy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "88938ba1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Array(368349, dtype=int32)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "count_unique_syndromes(final_s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "a9a7e8bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "master_plaquette_key = jax.random.PRNGKey(687090)\n",
    "plaquette_result = moebius_code_qubit.compute_batched_plaquette_syndrome_chi_x(\n",
    "    num_samples, em_moebius_qubit_jax, master_plaquette_key)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "6c122bbe",
   "metadata": {},
   "outputs": [],
   "source": [
    "plaquette_pads = -1 * jnp.ones(plaquette_result.shape[1] - 1)\n",
    "_, plaquette_probs = aggregate_data_jit(\n",
    "    plaquette_result,\n",
    "    num_samples,  # Passed as the static (Python int) argument\n",
    "    plaquette_pads\n",
    ")\n",
    "del plaquette_result\n",
    "del plaquette_pads"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "14e282aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "plaquette_conditional_entropy = miller_madow_conditional_entropy(\n",
    "    plaquette_probs, num_samples)\n",
    "del plaquette_probs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "383ec982",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Coherent information = -65402.00390625\n"
     ]
    }
   ],
   "source": [
    "coherent_info = 1.0 - vertex_conditional_entropy - plaquette_conditional_entropy\n",
    "print(\"Coherent information = {}\".format(coherent_info))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8e25ae8",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "coherentinfo",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
